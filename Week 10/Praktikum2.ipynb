{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZx1sDxeTVWgqdsAdjNm6L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ulfiizza27/2141720052-Machine-Learning-2023/blob/main/Week%2010/Praktikum2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Praktikum 2**\n",
        "## Generator Teks dengan RNN\n",
        "## **Setup**\n",
        "\n",
        "#### **Import TensorFlow**"
      ],
      "metadata": {
        "id": "OVFV4ecI7AAt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vyi16pCn67Rt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Download Dataset Shakespeare**\n",
        "\n",
        "Sesuaikan dengan lokasi data yang Anda punya."
      ],
      "metadata": {
        "id": "Wldfi_dI2RF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXAee2B29ods",
        "outputId": "e733ee8f-9799-4d52-d5e0-4321508fa60a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Load Data**"
      ],
      "metadata": {
        "id": "0URLcO6l2mKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcTfMflZ2bJd",
        "outputId": "0f337dd7-eaef-4bca-95cd-afbbc3134791"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyRGKeRq2sKa",
        "outputId": "79f394c7-7df5-4707-cde1-48df2d426142"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLTAhu-52t9C",
        "outputId": "e8c8be1a-5a96-4aa2-93c5-daba74aec221"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Olah Teks**\n",
        "Vectorize Teks\n",
        "\n",
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ],
      "metadata": {
        "id": "MT2v0Y7V2yG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHhkK4nK2vyq",
        "outputId": "9724d3f9-91eb-47ff-c4e6-41865ebaacdb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ],
      "metadata": {
        "id": "Zv5wr8RH4Dls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "FxkXJZQF3FD_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ],
      "metadata": {
        "id": "TCT9AszK4Ozt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n23_IuNk4GGQ",
        "outputId": "09174100-5145-4bfa-ba3a-cb51be507b94"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode tf.keras.layers.StringLookup(..., invert=True).\n",
        "\n",
        "Catatan: pada kode ini, daripada meneruskan kosakata asli yang dihasilkan dengan diurutkan(set(teks)) gunakan metode get_vocabulary() dari tf.keras.layers.StringLookup sehingga token [UNK] disetel dengan cara yang sama."
      ],
      "metadata": {
        "id": "gsx6H9Zk4fBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "-rJpJD-y4VRp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor:"
      ],
      "metadata": {
        "id": "Oy3KIXS94lfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwTGa4Oe4ipm",
        "outputId": "cb96c771-7493-4572-81c2-4c02796086cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anda dapat menggunakan tf.strings.reduce_join untuk menggabungkan kembali karakter menjadi string."
      ],
      "metadata": {
        "id": "HCbsOacX4sbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrMXMwbX4pLr",
        "outputId": "80f4ed37-b5e8-4b0d-9549-d22bb0c1612d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOzPHWyx4yCA",
        "outputId": "7a6e30c4-7648-4313-a14c-b6c562b5a8d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "6ql6PXmf40y3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Membuat Trianing Set dan Target**\n",
        "Selanjutnya bagilah teks menjadi contoh sequence. Setiap masukan sequence akan berisi karakter seq_length dari teks. Untuk setiap masukan sequence, target prediksi berisi teks dengan panjang yang sama, hanya digeser satu karakter ke kanan. Jadi, bagi teks menjadi beberapa bagian seq_length+1. Misalnya, seq_length adalah 4 dan teks kita adalah \"Hello\". Urutan masukannya adalah \"Hell\", dan urutan targetnya adalah \"ello\". Untuk melakukan ini, pertama-tama gunakan fungsi tf.data.Dataset.from_tensor_slices untuk mengonversi vektor teks menjadi aliran indeks karakter."
      ],
      "metadata": {
        "id": "G-YLU7_z6FLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZgSaJGa48U8",
        "outputId": "76d7d9bf-50b0-48fd-f86b-346f35478023"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "avtSXJGu6MZI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMKPHLda6b7U",
        "outputId": "150f9c33-c588-4e44-819c-a964fd4bcf93"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "E0Xne_zT6feB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ],
      "metadata": {
        "id": "cX0v8x4wJjuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "id": "JVHN783c6qnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19d3880-9004-46b4-f153-9286e466212c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ],
      "metadata": {
        "id": "7T7mR0KoJpLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAkAUYROJnRY",
        "outputId": "5cd17581-174a-4d25-c01c-6b5f82cff845"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ],
      "metadata": {
        "id": "UZFKet5zJySZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "vW2IHsRQJrHn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJefbsGdJ_Bb",
        "outputId": "cb054a35-9e61-49c4-a6a5-a9ed1f6c7914"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "qiDA-wtSKR5j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7oeODtoKVBR",
        "outputId": "44f75570-d35e-49f8-bd14-5b3bde8cd634"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Membuat Batch Training**\n",
        "\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ],
      "metadata": {
        "id": "qwhdtaD0KvOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hrC21tBKgWJ",
        "outputId": "20a2d59e-4b8c-4764-d797-3080ac05389c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Buat Model**\n",
        "\n",
        "Bagian ini mendefinisikan model sebagai subkelas keras.Model (untuk lebih detilnya, lihat Making new Layers and Models via subclassing).\n",
        "\n",
        "Model yang kita bangun memiliki 3 lapisan neural network :\n",
        "\n",
        "- tf.keras.layers.Embedding: Lapisan masukan. Tabel pencarian yang dapat dilatih yang akan memetakan setiap karakter-ID ke vektor dengan dimensi embedding_dim;\n",
        "- tf.keras.layers.GRU: lapisan RNN dengan ukuran unit=rnn_units (Anda juga dapat menggunakan lapisan LSTM di sini.)\n",
        "- tf.keras.layers.Dense: Lapisan keluaran, dengan keluaran vocab_size. Ini menghasilkan satu logit untuk setiap karakter dalam kosakata. Ini adalah log kemungkinan setiap karakter menurut model."
      ],
      "metadata": {
        "id": "c2dHShy6K4M_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "FPSYbiNNK0Nb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "WgQYwETLLHqY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "2CHtpmgvLJXO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Uji Model**\n",
        "\n",
        "Coba jalankan model dan cek apakah sidah sesuai dengan output\n",
        "pertama, cek bentuk dari output"
      ],
      "metadata": {
        "id": "MElbnfSULOMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jvIe6HuLKrg",
        "outputId": "49013d54-6133-4613-db94-3d85e54b2929"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam contoh di atas, panjang urutan masukan adalah 100 tetapi model dapat dijalankan pada masukan dengan panjang berapa pun:"
      ],
      "metadata": {
        "id": "wFRhf-s9Li9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cosgf7MkLUCW",
        "outputId": "042ab5b7-8018-4d71-9199-7e3332c270b3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk mendapatkan prediksi aktual dari model, Anda perlu mengambil sampel dari distribusi keluaran, untuk mendapatkan indeks karakter aktual. Distribusi ini ditentukan oleh logit pada kosakata karakter. Catatan: Penting untuk mengambil sampel dari distribusi ini karena mengambil argmax dari distribusi tersebut dapat dengan mudah membuat model terjebak dalam infinote loop. Cobalah untuk contoh pertama di batch:"
      ],
      "metadata": {
        "id": "g3Jr0uSMLpE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "AgTBT6gZLl0g"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hal ini memberi kita, pada setiap langkah waktu, prediksi indeks karakter berikutnya:"
      ],
      "metadata": {
        "id": "aizbuP9-LywP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-MMQEQULq5p",
        "outputId": "cd7d8afb-33df-46a5-ca58-0c52f75b655f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([55, 32,  3, 61, 64, 62, 13, 27, 42, 31, 58, 35,  5, 32, 32, 31, 42,\n",
              "       27, 56, 45,  1, 35,  3,  8, 18, 26, 47, 28,  2, 26, 42, 12, 53, 33,\n",
              "        8, 14, 60, 39, 18, 45, 50, 15, 25, 17, 16, 13, 23, 28, 65, 11, 40,\n",
              "       37, 59, 23, 34, 56, 51,  8, 52, 40, 19, 16,  1, 56, 10,  6,  1, 38,\n",
              "       53, 33, 32, 50, 31, 53, 53, 20, 25, 55, 37,  3, 25, 24,  3, 12, 50,\n",
              "       42, 16, 23, 23, 18, 58, 57,  2, 62, 29, 40, 30, 38, 38,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ],
      "metadata": {
        "id": "ltPcMzh1L2Zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZvFD3HPL0ot",
        "outputId": "5a3e936b-7220-4f55-e017-fca0dc2e82f0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b' I scorn his worthless threats!\\n\\nYORK:\\nWill you we show our title to the crown?\\nIf not, our swords s'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"pS!vyw?NcRsV&SSRcNqf\\nV!-EMhO Mc;nT-AuZEfkBLDC?JOz:aXtJUql-maFC\\nq3'\\nYnTSkRnnGLpX!LK!;kcCJJEsr wPaQYY \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train Model**\n",
        "\n",
        "Pada titik ini permasalahan dapat dianggap sebagai permasalahan klasifikasi standar. Permasalahan dapat disimpulkan dengan : Berdasarkan status RNN sebelumnya, dan masukan langkah kali ini, prediksi kelas karakter berikutnya.\n",
        "\n",
        "##### **Tambahan optimizer dan fungsi loss**\n",
        "\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits."
      ],
      "metadata": {
        "id": "KrA40jq_MMWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "3-OgOXJ_L4EW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAhbASNNMYN9",
        "outputId": "4e13b2e7-655e-422f-fb19-b693d87bc3a1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1889763, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ],
      "metadata": {
        "id": "ft2xL5PpMiA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcP8dG0FMf__",
        "outputId": "e77880a0-f8e6-4503-bdee-b3bd93532eba"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.95524"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ],
      "metadata": {
        "id": "ucY5x2UIMqBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "xfAmAFnVMoT_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Konfigurasi Checkpoints**\n",
        "\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ],
      "metadata": {
        "id": "ay9hZN8PMx_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "itCnYC8vMsOn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Lakukan Proses Training**\n",
        "\n",
        "Agar waktu pelatihan tidak terlalu lama, gunakan 10 epoch untuk melatih model. Di Colab, setel runtime ke GPU untuk pelatihan yang lebih cepat."
      ],
      "metadata": {
        "id": "bmF8f0hnM4Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "2BFz0JSEM2uT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElUOAmuIM8mn",
        "outputId": "64c96e30-26f8-4791-8f4c-1c6939cbb3fd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 13s 52ms/step - loss: 2.6870\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 11s 49ms/step - loss: 1.9670\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 11s 50ms/step - loss: 1.6868\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 13s 50ms/step - loss: 1.5299\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 11s 51ms/step - loss: 1.4360\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 10s 51ms/step - loss: 1.3694\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 10s 51ms/step - loss: 1.3187\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 10s 52ms/step - loss: 1.2741\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.2330\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.1928\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.1530\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.1107\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.0663\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 12s 53ms/step - loss: 1.0202\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 54ms/step - loss: 0.9702\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 0.9185\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.8655\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.8139\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.7628\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.7155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Generate Teks**\n",
        "\n",
        "Setiap kali Anda memanggil model, Anda memasukkan beberapa teks dan state internal. Model mengembalikan prediksi untuk karakter berikutnya dan state barunya. Masukkan kembali prediksi dan state ke model untuk terus menghasilkan teks."
      ],
      "metadata": {
        "id": "7Prg-zS-NIye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "QbjCfkh6NClI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "lgIOzXbRNZvk"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jalankan secara berulang untuk menghasilkan beberapa teks. Melihat teks yang dihasilkan, Anda akan melihat model mengetahui kapan harus menggunakan huruf besar, membuat paragraf, dan meniru kosakata menulis seperti Shakespeare. Karena sedikitnya jumlah epoch pelatihan, model belum belajar membentuk kalimat runtut."
      ],
      "metadata": {
        "id": "ocOYwlQhNfAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrmIt5B_Nh0t",
        "outputId": "f5a2aff2-267f-4ddc-f9f2-c74fb88271b9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "That shows good gates where the maid both Bonable\n",
            "Laugh mumory impeach'd.\n",
            "Now seemed is but to give thy house to-night at once,\n",
            "Or more consul, and other more\n",
            "Than all the spring to their sufferance.\n",
            "\n",
            "GLOUCESTER:\n",
            "Good morror, prithee, bring thee now to pluck more than a\n",
            "creputualing tongue.\n",
            "\n",
            "ANGELO:\n",
            "Well, Petruchio, my lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Bring me to the Earl of Pisa.\n",
            "'Tis to my good lord.\n",
            "\n",
            "KING RICHARD III:\n",
            "Give me a cord, and do you till now\n",
            "Come resumpted to your stomation;\n",
            "Yiely please, forget to do, and after the priest\n",
            "And frown hath made my state and state of others,\n",
            "Of this forgiveness of your body, young\n",
            "matter being owes to know of you.\n",
            "More than I wish to warn or foul is here\n",
            "at home for life.\n",
            "\n",
            "ISABELLA:\n",
            "Mistress Ovison; I know the daur\n",
            "constrains the fliers at first, for one word.\n",
            "\n",
            "PRINCE:\n",
            "Wilt thou read their man o' retalf?\n",
            "\n",
            "KING EDWARD IV:\n",
            "Brave flaurish'd Romeo's smile, at Philit,\n",
            "Nor that by me with your ears to give the waves.\n",
            "Account my peace is banish'd father, E \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.9782938957214355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hal termudah yang dapat Anda lakukan untuk meningkatkan hasil adalah dengan melatihnya lebih lama (coba EPOCHS = 30). Anda juga dapat bereksperimen dengan string awal yang berbeda, mencoba menambahkan lapisan RNN lain untuk meningkatkan akurasi model, atau menyesuaikan parameter suhu untuk menghasilkan prediksi yang kurang lebih acak.\n",
        "\n",
        "Jika Anda ingin model menghasilkan teks lebih cepat, hal termudah yang dapat Anda lakukan adalah membuat teks secara batch. Pada contoh di bawah, model menghasilkan 5 keluaran dalam waktu yang hampir sama dengan waktu yang dibutuhkan untuk menghasilkan 1 keluaran di atas."
      ],
      "metadata": {
        "id": "TXkD3A5tNl6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFy8hEBINoXb",
        "outputId": "ba413131-66fa-47e8-eb40-e4bc628eba4a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nYou have misca'd to her.\\n\\nSICINIUS:\\nBe with me\\nThe watch that I. Do you have resolved to him ere this:\\nThy brother's best friends,--Hiften to his surman of it?\\nShart, when you should hate thee deadly son's\\nwings that you have villain womb again?\\n\\nROMEO:\\nOur speech was high? bid them govern our hotiness\\nAs the false of his authority,\\nThy swift will slain with him in all;\\nBut for some other permition\\nWipe of great nature cries 'Remember mine.\\n\\nEDWARD:\\nFarewell, beseech your highness: my master,\\nCharged me the faults,--Officer, sir, and spit\\nTo him that settled shepherd's hand.\\n\\nDUKE OF YORK:\\nIt issue from sharper, more power.\\n3 crave below, give me they are right, 'tis not this my\\nson and make fashions to command; where and\\nthou camest to pierce out a spicit again!\\nConfear more; and therefore I will turn you\\nspeak, or else his head.\\n\\nRICHARD:\\nI Prite up thy necessance! Was time to friends.\\n\\nROMEO:\\nQuate Persun, gentle Sir Jamnords:\\nSo it is much, knees he make:\\nWhen this is true, youngl\"\n",
            " b\"ROMEO:\\nBesides, you shall not be your wise: which would he had\\nalike brief-from me and let me see--\\nFor yet his or house or bread, this is your anchy's\\nformer, itself is made be streak'd all all within the sentence\\nThat you shall, nor string that lift:\\nAnd yet, it is your tribunes to the wall.\\n\\nHASTINGS:\\nI volume him, and expresh him out\\nOur rises, whiles I firmly ves doth ut\\ntake or courtesy.\\n\\nSICINIUS:\\nRepent, brays, or thou hast\\nWhere's the liking of thy words,\\nIn those that I had surn'd my secret hope,\\nShalt feel your son, as mine hath stalt,\\nAnd here you born in janquest.\\n\\nSORIOLENSEROMIO:\\nStraves not 'gainst the worst with you.\\n\\nKATHARINA:\\nNo; I come to you.\\n\\nBRUTUS:\\nOnly makes thee--\\n\\nNurse:\\nFalse well my heart!\\n\\nHASTINGS:\\nAnd thrive hurriedged meecius:\\nThe daughters of those fleeces fails of grace\\nAnd make me well I wot you have this,\\nWhen the army, is it to Lulician Nothing gold\\nAnd fet me but one happy tale; then entreat your green\\nEdward tupols for it. O, it prites that evil,\\nWher\"\n",
            " b\"ROMEO:\\nYou cannot say, for it rew'st to the Volsa, till I leave\\nWotiniby-toge all in pride of thine oracle,\\nAnd to my shame in parlian.\\n\\nKATHARINA:\\nNie time the hoop is spare:\\nAnd speak I cannot prove a traitor to the capain;\\nAnd so, proud, stay, keep'st thou, speed! O thank you\\ngo,\\nLet him not so.\\n\\nDUKE VINCENTIO:\\nAy, it is too late us alus, fly in older crutch\\nBerovided again which if you had,\\nAnd over-ever woman in this place,\\nOr list thou thine other way\\nFie deal upon my pack of this.\\n\\nCAMILLO:\\nO miserable lady!\\nAncient manicisa,\\nFarewell of uncle Camillo to this merchand'st adreg.\\n\\nGREMIO:\\nFour daughter is coming, or then in executioner,\\nCould I most gladless prayers for beful. Come on, my lord,\\nAnd len the ears able York's death is thine.\\n\\nPRINCE EDWARD:\\nAn is detointed or other circumment,\\nYour igns against me in thy leisure,\\nIn his tongue to think of Ane? fly in thy speech and his\\nfriends,\\nmother, I hear, the terror of the name of men.\\n\\nNORTHUMBERLAND:\\nWhy, that's my fortune, for\\none\"\n",
            " b\"ROMEO:\\nThe unquestany gods brings my trusts and lady:\\n'Tis so well for that love to her.\\n\\nGLOUCESTER:\\n\\nCLARENCE:\\n\\nGhost of YORK:\\nUpon my wife!\\n\\nSLY:\\nMy gorand rest!\\nPoor Souard, must I contempt.\\n\\nMARCIUS:\\nSeek so, yourself as much as to our happy days.\\n\\nRICHARD:\\nSay, it every nare, my lord! which, at home between;\\nPrinceed thus, his majest for this, voice\\nArmountant to hear again; but if I fle?\\nThe old man who shall tell me thence.\\n\\nMARCIUS:\\nI thought is your fancy, is true and with\\nthe power that you speak a lith tune and in\\nAny old leg-s ready not so high a\\ncortlivant.\\n\\nProvost:\\nI come, it!\\n\\nClown:\\nHillo! I promised me to the common grief\\nThere's posterity Stock him for his report:\\nI long how first your summer course than heaven,\\nHis yielded for your hate.\\n\\nCLAUDIO:\\nKeep Clarence were your warlike dream: only like your\\nfavours is full of earsh. So sat their deaths thy father\\nYou like infilenced to his grave.\\n\\nJOHN OF GAUNT:\\nWhat, ho! speak not to this enter Master Clarence but\\ndischarend l\"\n",
            " b\"ROMEO:\\nI pray you, life one word.\\n\\nNORTHUMBERLAND:\\nWhether it be forbid:' to infarm thee, knees, and leaves\\nI learned in your wards.\\n\\nVINCENWIO:\\nBring forth, and embrace with you; but thou'rt too late!\\n\\nTo leaven pine of good course,\\nStrike up this grace had been a solern. What, shall we to?\\nNow over that celtared them, as you gentleman is\\nTurned me, as I have seem your good sweet is.\\n\\nLUCENTIO:\\nI protest I make with all;\\nAnd for the man and Richard kill'd him:\\nI mind to serve God, hollow man, whether I stray,\\nMuch evil diedless villains, nay, come again,\\nHow stamp'd the sister o' the city,\\n'fore men flug tager, and so discredit die.\\n\\nKING RICHARD III:\\nMine eyes, or go along; O, I\\nat the farthest forbidge of the life of all.\\n\\nPRINCE EDWARD:\\nA bridagen till you by my wrong: I am too.\\n\\nMOPSA:\\nPray you, in whose inclusion shame to have no old too?\\n\\nBUCKINGHAM:\\nRather than command them to our groats; whenesher\\nMight have meddled again by the iceror?\\n\\nMakind Angelo hath set\\nmy wife's a master and\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.2565248012542725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Ekspor Model Generator**\n",
        "\n",
        "Model satu langkah ini dapat dengan mudah disimpan dan digunakan kembali, memungkinkan Anda menggunakannya di mana pun tf.saved_model diterima."
      ],
      "metadata": {
        "id": "_j2y-MD3NqpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WezK6JGMNu0k",
        "outputId": "443f3fec-d187-4ac2-bc73-404f78d7f9d6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x786cbc33ff10>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M0qgPVVNwac",
        "outputId": "ce176c07-b437-4d8a-a02c-fe5feddc2419"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "It was his human patricians!' may well wish\n",
            "You spoke of this actions, all as to prepare.\n",
            "\n",
            "BALTHASA\n"
          ]
        }
      ]
    }
  ]
}